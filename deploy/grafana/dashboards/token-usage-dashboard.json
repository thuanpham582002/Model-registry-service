{
  "title": "Model Registry - Token Usage (OpenTelemetry Gen AI)",
  "uid": "model-registry-tokens",
  "editable": true,
  "time": {
    "from": "now-24h",
    "to": "now"
  },
  "refresh": "1m",
  "panels": [
    {
      "id": 1,
      "title": "Token Usage by Model",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "targets": [
        {
          "expr": "sum by (gen_ai_request_model) (rate(gen_ai_client_token_usage_sum[5m]))",
          "legendFormat": "{{gen_ai_request_model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "tokens/s"
        }
      }
    },
    {
      "id": 2,
      "title": "Input vs Output Tokens",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "targets": [
        {
          "expr": "sum by (gen_ai_token_type) (rate(gen_ai_client_token_usage_sum[5m]))",
          "legendFormat": "{{gen_ai_token_type}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "tokens/s"
        }
      }
    },
    {
      "id": 3,
      "title": "Request Duration (P99)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
      "targets": [
        {
          "expr": "histogram_quantile(0.99, sum by (le, gen_ai_request_model) (rate(gen_ai_server_request_duration_bucket[5m])))",
          "legendFormat": "{{gen_ai_request_model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        }
      }
    },
    {
      "id": 4,
      "title": "Time to First Token (P50)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le, gen_ai_request_model) (rate(gen_ai_server_time_to_first_token_bucket[5m])))",
          "legendFormat": "{{gen_ai_request_model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "s"
        }
      }
    },
    {
      "id": 5,
      "title": "Time Per Output Token (P50)",
      "type": "timeseries",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 16 },
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum by (le, gen_ai_request_model) (rate(gen_ai_server_time_per_output_token_bucket[5m])))",
          "legendFormat": "{{gen_ai_request_model}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ms"
        }
      }
    },
    {
      "id": 6,
      "title": "Top 10 Models by Token Usage (24h)",
      "type": "bargauge",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 16 },
      "targets": [
        {
          "expr": "topk(10, sum by (gen_ai_request_model) (increase(gen_ai_client_token_usage_sum[24h])))",
          "legendFormat": "{{gen_ai_request_model}}"
        }
      ],
      "options": {
        "orientation": "horizontal",
        "displayMode": "gradient"
      }
    },
    {
      "id": 7,
      "title": "Total Tokens (24h)",
      "type": "stat",
      "gridPos": { "h": 4, "w": 4, "x": 0, "y": 24 },
      "targets": [
        {
          "expr": "sum(increase(gen_ai_client_token_usage_sum[24h]))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short"
        }
      }
    },
    {
      "id": 8,
      "title": "Input Tokens (24h)",
      "type": "stat",
      "gridPos": { "h": 4, "w": 4, "x": 4, "y": 24 },
      "targets": [
        {
          "expr": "sum(increase(gen_ai_client_token_usage_sum{gen_ai_token_type=\"input\"}[24h]))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short"
        }
      }
    },
    {
      "id": 9,
      "title": "Output Tokens (24h)",
      "type": "stat",
      "gridPos": { "h": 4, "w": 4, "x": 8, "y": 24 },
      "targets": [
        {
          "expr": "sum(increase(gen_ai_client_token_usage_sum{gen_ai_token_type=\"output\"}[24h]))"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "short"
        }
      }
    },
    {
      "id": 10,
      "title": "Requests by Operation",
      "type": "piechart",
      "gridPos": { "h": 8, "w": 8, "x": 12, "y": 24 },
      "targets": [
        {
          "expr": "sum by (gen_ai_operation_name) (increase(gen_ai_server_request_duration_count[24h]))",
          "legendFormat": "{{gen_ai_operation_name}}"
        }
      ]
    }
  ]
}
